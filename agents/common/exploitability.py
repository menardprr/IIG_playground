from functools import partial

import jax
import jax.numpy as jnp
import numpy as np

import pyspiel
from open_spiel.python import policy
from open_spiel.python.algorithms import exploitability

from games.full_liars_dice import round_to_full


class Exploitability:
    """Class to compute exploitability via Nash conv of OpenSpiel"""

    def __init__(self, game_name, get_logit, mini_batch_size=512):
        self.transform = None
        os_game_name = game_name
        if game_name == "leduc_poker":
            os_game_name = "leduc_poker(players=2,suit_isomorphism=True)"
        if (game_name == "full_liars_dice") or (game_name == "full_liars_dice_w1"):
            os_game_name = "liars_dice"
            _round_to_full = partial(
                round_to_full, num_dice=1, max_num_dice=5, dice_sides=6)
            self.transform = jax.vmap(_round_to_full, (0, 0), (0, 0))
        # Open spiel game
        self.game = pyspiel.load_game(os_game_name)
        # Tabular policy
        self._tab_policy = policy.TabularPolicy(self.game)
        states = self._tab_policy.states
        # Get all batched obs and legal
        obs = jnp.stack(
            [jnp.array(state.information_state_tensor(), dtype=jnp.bool_)
             for state in states],
            axis=0
        )
        legal = jnp.stack(
            [jnp.array(state.legal_actions_mask(), dtype=jnp.bool_)
             for state in states],
            axis=0,
        )
        if self.transform is not None:
            obs, legal = self.transform(obs, legal)
        # Change type
        obs = jnp.float32(obs)
        legal = jnp.int8(legal)
        # Get minibatch
        self.obs = self.get_mini_batch(obs, mini_batch_size)
        self.legal = self.get_mini_batch(legal, mini_batch_size)
        # Get compute policy table

        def compute_policy_table(params, obs, legal):
            rollout = jax.vmap(get_logit, (None, 0, 0), (0, 0, 0))
            _, _, pi = rollout(
                params,
                obs,
                legal
            )
            return jnp.reshape(pi, (-1,) + pi.shape[2:])
        self._compute_policy_table = jax.jit(partial(
            compute_policy_table,
            obs=self.obs,
            legal=self.legal,
        ))

    def get_mini_batch(self, x, mini_batch_size=513):
        """Get batched version of a tensor"""
        padding = x.shape[0] % mini_batch_size
        padding = (mini_batch_size - padding) * (padding > 0)
        pad = jnp.ones_like(x, shape=(padding,) + x.shape[1:])
        x = jnp.append(x, pad, axis=0)
        return jnp.reshape(x, (-1, mini_batch_size) + x.shape[1:])

    def _get_tab_policy(self, params):
        """Get a tabular policy from policy defined by params"""
        policy_table = self._compute_policy_table(params)
        self._tab_policy.action_probability_array = np.array(
            policy_table[:len(self._tab_policy.states)])
        # tab_policy = policy.TabularPolicy(self.game)
        # tab_policy.action_probability_array = np.array(policy_table[:len(tab_policy.states)])
        return self._tab_policy

    def compute_exploitability(self, params):
        """Compute the exploitability of policy defined by params"""
        # get the tabular policy
        profile = self._get_tab_policy(params)
        # return the exploitability
        return exploitability.nash_conv(
            self.game,
            profile,
            return_only_nash_conv=False,
            use_cpp_br=True
        )
